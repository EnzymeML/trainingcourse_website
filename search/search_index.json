{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#why-enzymeml","title":"Why EnzymeML?","text":""},{"location":"#unlock-the-full-potential-of-your-biocatalytical-data","title":"Unlock the Full Potential of Your Biocatalytical Data","text":"<p>This training course is designed to empower researchers, scientists, and data analysts in biocatalysis by equipping them with the skills to manage and analyze experimental data beyond traditional Excel workflows. By leveraging Python and AI-driven tools, participants will enhance their ability to structure, process, and interpret complex datasets while ensuring adherence to FAIR data principles.</p>"},{"location":"#goals","title":"Goals","text":""},{"location":"#1-move-beyond-excel-smarter-data-management","title":"1. Move Beyond Excel: Smarter Data Management","text":"<p>Excel is a widely used tool in biocatalysis, but it has limitations when handling large-scale, multidimensional datasets. This course provides participants with alternative approaches that allow for:</p> <ul> <li>Efficient data structuring and processing.</li> <li>Automated workflows that reduce errors and improve reproducibility.</li> <li>Scalable solutions for large datasets that exceed Excel's capabilities.</li> </ul>"},{"location":"#2-apply-python-directly-to-your-research-data","title":"2. Apply Python Directly to Your Research Data","text":"<p>Unlike generic coding courses that rely on theoretical examples, this training is focused on your own experimental data. Participants will:</p> <ul> <li>Work with their real-world datasets from their research projects.</li> <li>Learn how to manipulate and analyze biocatalytical data using Python.</li> <li>Gain hands-on experience in integrating computational tools into their workflows.</li> </ul>"},{"location":"#3-simplified-python-learning-with-ai-assistance","title":"3. Simplified Python Learning with AI Assistance","text":"<p>For participants new to Python, the learning curve can be steep. This course integrates AI-driven tools to facilitate:</p> <ul> <li>Code generation and debugging support.</li> <li>Step-by-step guidance in writing and optimizing Python scripts.</li> <li>Automated solutions for routine data processing tasks.</li> </ul>"},{"location":"#4-ensure-fair-compliance-with-enzymeml","title":"4. Ensure FAIR Compliance with EnzymeML","text":"<p>The course emphasizes FAIR-compliant data management, ensuring that experimental results are:</p> <ul> <li>Findable \u2013 Easily searchable and indexed for future reference.</li> <li>Accessible \u2013 Structured in a way that allows seamless data sharing.</li> <li>Interoperable \u2013 Compatible with other datasets and computational tools.</li> <li>Reusable \u2013 Properly documented and standardized to support further research.</li> </ul> <p>Through hands-on training, participants will learn how to generate EnzymeML documents, a standardized format for enzymatic reaction data that enhances data exchange and reproducibility.</p>"},{"location":"publications/","title":"Publications","text":""},{"location":"publications/#2024","title":"2024","text":"<ul> <li>EnzymeML: seamless data flow and modeling of enzymatic data (Nat. Meth.)</li> </ul>"},{"location":"publications/#2023","title":"2023","text":"<ul> <li>EnzymeML: seamless data flow and modeling of enzymatic data (Nat. Meth.)</li> </ul>"},{"location":"team/","title":"Team","text":""},{"location":"team/#developers","title":"Developers","text":"<ul> <li>Jan Range (UX/UI Designer)</li> <li>Max H\u00e4ussler</li> <li>Torsten Giess</li> </ul>"},{"location":"team/#scientific-coordinators","title":"Scientific Coordinators","text":"<ul> <li>J\u00fcrgen Pleiss</li> </ul>"},{"location":"team/#former-developers","title":"Former Developers","text":"<ul> <li>Stephan Malzacher</li> </ul>"},{"location":"sessions/01-overview/","title":"Availabe tools for processing of experimental data","text":""},{"location":"sessions/01-overview/#from-raw-experimental-data-to-enzymeml-driven-analysis","title":"From Raw Experimental Data to EnzymeML-Driven Analysis","text":"<p>Processing experimental data for analysis is often a complex and error-prone task. Typically, raw data from lab instruments such as plate readers, chromatographs, and NMR devices must be manually extracted, cleaned, and reformatted before analysis can begin. This process is time-consuming and not scalable.</p> <p>To streamline this workflow, Python tools such as chromatopy, MTPHandler, and NMRpy have been developed. These tools enable direct reading of raw data files from experimental instruments, automating the transformation into a structured format that is immediately usable for analysis.</p>"},{"location":"sessions/01-overview/#data-processing-workflow","title":"Data Processing Workflow","text":"<p>Raw data is read directly from files generated by lab instruments and transformed into EnzymeML documents. EnzymeML provides a standardized structure for storing key reaction data, including reaction conditions, catalysts, and substrate properties. This ensures that data is well-organized, FAIR-compliant, and ready for computational analysis.</p> <p>Within a Jupyter Notebook environment, these tools allow seamless integration of data processing, analysis, and visualization. The entire workflow\u2014from raw data ingestion to structured analysis\u2014is transparent, reproducible, and easy to share with others.</p> <p>For more details on the EnzymeML format, please refer to the EnzymeML specification.</p>"},{"location":"sessions/01-overview/#from-raw-data-to-analyzable-data","title":"From Raw Data to Analyzable Data","text":"<p>Once experimental data has been transformed into EnzymeML format, it becomes the foundation for further data science applications:</p> <ul> <li>Yield, conversion, and selectivity calculations</li> <li>Kinetic modeling and reaction simulations</li> <li>Comprehensive visualization of experimental results</li> </ul> <p>The following diagram shows the workflow from raw data to analyzable data in form of an EnzymeML Document:</p> <pre><code>graph LR\n    A[\ud83c\udf08 Chromatographic Instrument] --&gt;|output| A1[\ud83d\udcc4 Files]\n    B[\ud83d\udd2c Plate Reader] --&gt;|output| B1[\ud83d\udcc4 Files]\n    C[\ud83e\uddf2 NMR] --&gt;|output| C1[\ud83d\udcc4 Files]\n\n    A1 --&gt;|read| D\n    B1 --&gt;|read| E\n    C1 --&gt;|read| F\n\n    subgraph in Jupyter Notebook:\n        subgraph Experimental Data Processing\n            D{chromatopy}\n            E{MTPHandler}\n            F{NMRpy}\n        end\n        D --&gt;|transform| DataObject[EnzymeML Object]\n        E --&gt;|transform| DataObject\n        F --&gt;|transform| DataObject\n        DataObject -.-&gt; DS1\n        DataObject &lt;-.-&gt; DS2\n        DataObject -.-&gt; DS3\n        subgraph with Data Science Python Tools:\n            DS1[Determine e.g., yield, conversion, selectivity]\n            DS2[Kinetic Modeling]\n            DS3[Visualization]\n        end\n    end\n    DataObject --&gt;|transform| ExperimentalDocument\n    ExperimentalDocument[\"&lt;b&gt;\ud83d\udcc4 EnzymeML Document&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;Small Molecules&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Proteins&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Measurements&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Reactions&lt;/i&gt;\"]</code></pre>"},{"location":"sessions/01-overview/#photometric-data","title":"\ud83d\udd2c Photometric Data","text":"<p>The MTPHandler Python library streamlines the processing of photometric data from plate readers. It enables reading, processing, and exporting data from a variety of plate reader formats, blank correction, and concentration calculation in a scalable way.</p>"},{"location":"sessions/01-overview/#chromatographic-data","title":"\ud83c\udf08 Chromatographic Data","text":"<p>The Chromatopy Python library streamlines the processing of chromatographic time-course data. It enables reading, processing, and exporting data from a variety of chromatographic instruments, assignment of retention times to molecules, and concentration calculation in a scalable way.</p>"},{"location":"sessions/01-overview/#nmr-data","title":"\ud83e\uddf2 NMR Data","text":"<p>The NMRPy Python library streamlines the processing of NMR time-course data.</p>"},{"location":"sessions/02-programming-setup/","title":"Programming Setup","text":""},{"location":"sessions/02-programming-setup/#required-software","title":"Required Software","text":""},{"location":"sessions/02-programming-setup/#1-cursor-ide","title":"1. Cursor IDE","text":"<p>Cursor is an AI-powered code editor that can help you write code faster and more efficiently. For more information and to install it, please visit the Cursor website.</p>"},{"location":"sessions/02-programming-setup/#2-python-environment","title":"2. Python Environment","text":"<p>We'll use Conda as our Python environment manager. It's available for Windows, macOS, and Linux.</p>"},{"location":"sessions/02-programming-setup/#installing-conda","title":"Installing Conda","text":"<p>Choose one of these distributions: - Miniconda: Lightweight version - Anaconda: Full package suite - Miniforge: Community-driven version</p>"},{"location":"sessions/02-programming-setup/#windows-installation","title":"Windows Installation","text":"<ol> <li>Download the installer from your chosen distribution</li> <li>Run the <code>.exe</code> file and follow the installation wizard</li> <li>Verify installation by opening Anaconda/Miniforge Prompt:    <pre><code>conda list\n</code></pre></li> </ol>"},{"location":"sessions/02-programming-setup/#macos-installation","title":"macOS Installation","text":"<ol> <li>Download your chosen installer</li> <li>Open terminal and run:    <pre><code>bash &lt;conda-installer-name&gt;-latest-MacOSX-x86_64.sh\n</code></pre></li> <li>Close and reopen terminal</li> <li>Verify installation:    <pre><code>conda list\n</code></pre></li> </ol>"},{"location":"sessions/02-programming-setup/#linux-installation","title":"Linux Installation","text":"<ol> <li>Download Miniconda:    <pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n</code></pre></li> <li>Install:    <pre><code>bash Miniconda3-latest-Linux-x86_64.sh\n</code></pre></li> <li>Restart terminal</li> <li>Verify installation:    <pre><code>conda list\n</code></pre></li> </ol>"},{"location":"sessions/02-programming-setup/#working-with-conda-environments","title":"Working with Conda Environments","text":""},{"location":"sessions/02-programming-setup/#creating-environments","title":"Creating Environments","text":"<p>Create a new environment with specific Python version and packages: <pre><code>conda create -n my_project_env python=3.10 numpy pandas\n</code></pre></p>"},{"location":"sessions/02-programming-setup/#managing-environments","title":"Managing Environments","text":"<ul> <li>Activate an environment:   <pre><code>conda activate my_project_env\n</code></pre></li> <li>List all environments:   <pre><code>conda env list\n# or\nconda info --envs\n</code></pre></li> <li>Install packages in active environment via <code>pip</code>:   <pre><code>pip install scipy matplotlib\n</code></pre></li> </ul>"},{"location":"sessions/02-programming-setup/#ide-setup","title":"IDE Setup","text":""},{"location":"sessions/02-programming-setup/#setting-up-conda-in-cursorvscode","title":"Setting Up Conda in Cursor/VSCode","text":"<ol> <li> <p>Activate your environment:    <pre><code>conda activate my_project_env\n</code></pre></p> </li> <li> <p>Install Jupyter kernel:    <pre><code>conda install ipykernel\n</code></pre></p> </li> <li> <p>Configure VSCode:</p> </li> <li>Install Python extension from marketplace</li> <li>Press <code>Ctrl + Shift + P</code> (or <code>Cmd + Shift + P</code> on macOS)</li> <li>Search for \"Select Python Interpreter\"</li> <li>Choose your Conda environment</li> </ol>"},{"location":"sessions/03-read-experimental-data/","title":"Read Experimental Data","text":""},{"location":"usecases/chromatography/","title":"Process Chromatographic Data","text":"<p>In this hackathon session, you will process your own chromatographic data using the <code>chromatopy</code> Python package. Alternatively, if you do not have your own data, or something fails, you can use the provided example data.</p>"},{"location":"usecases/chromatography/#topics","title":"\ud83d\udcda Topics","text":"<ol> <li>You will get familiar with using Jupyter Notebooks and how you can run Python code locally on your computer.</li> <li>You will learn how to process and enrich your chromatographic data using the <code>chromatopy</code> Python package.</li> <li>You will yield a structured EnzymeML Document that can be used for further data analysis.</li> </ol>"},{"location":"usecases/chromatography/#setup","title":"\ud83d\udee0\ufe0f Setup","text":""},{"location":"usecases/chromatography/#start-jupyter-notebook","title":"Start Jupyter Notebook","text":"<p>Start with opening Anaconda and launching a Jupyter Notebook. If this is the first time you ever used a Jupyter Notebook, you can find a short introduction  here. Otherwise, you can skip this step.</p>"},{"location":"usecases/chromatography/#setup-a-project-folder-and-notebook","title":"Setup a project folder and notebook","text":"<p>Navigate to your desired location and create a new folder for your project. This folder will contain all the files you will create during this session. Afterwards, create a new Jupyter Notebook in this folder. You can create new folders and the notebook directly from the Jupyter Notebook interface. Therefore, you can use the <code>New</code> button in the top right corner and select <code>Folder</code> or <code>Notebook Python3 (ipykernel)</code>.</p>"},{"location":"usecases/chromatography/#add-the-data-to-your-project-folder","title":"Add the data to your project folder","text":"<p>If you brought your own chromatographic data... If you brought your own chromatographic file, add it to the project folder. Please make sure that your data is organized and processed in a way that it can be read by the <code>chromatopy</code> package. You can find the supported formats and data preparation in the documentation of <code>chromatopy</code>.</p> <p>If you do not have your own data... If you do not have your own data, you can download the example data set and add it to your project folder.</p>"},{"location":"usecases/chromatography/#install-the-chromatopy-package","title":"Install the <code>chromatopy</code> package","text":"<p>Copy the following code snippet into the first cell of your Jupyter Notebook and run it. This code snippet will install the <code>chromatopy</code> package if it is not already installed. This is a one-time setup and will not be required for future sessions.</p> <pre><code>import sys\nimport subprocess\nimport shutil\n\n# install git via conda if not installed\nif not shutil.which(\"git\"):\n    print(\"Installing git via conda\")\n    subprocess.run([\"conda\", \"install\", \"-y\", \"git\"])\n    if not shutil.which(\"git\"):\n        print(\"git is not installed\")\n        sys.exit(1)\nprint(\"git is installed\")\n\n# install chromatopy\ntry:\n    from chromatopy import ChromAnalyzer\nexcept ImportError:\n    print(\"Installing chromatopy...\")\n    !pip install git+https://github.com/FAIRChemistry/chromatopy.git\nprint(\"\ud83c\udfc1 All set! Restart the Notebook once and you are ready to go.\")\n</code></pre> <p>After you have run this code snippet, restart the Jupyter Notebook. You can do this by clicking on <code>Kernel</code> &gt; <code>Restart Kernel...</code> in the top menu, or by clicking on the  button in the top.</p> <p>Verify that the installation was successful by running the following code snippet in a new cell:</p> <pre><code>from chromatopy import ChromAnalyzer\n</code></pre> <p>If you do not get an error message, the installation was successful and the <code>ChromAnalyzer</code> is ready to use. Otherwise, please let us know.</p>"},{"location":"usecases/chromatography/#start-using-the-chromanalyzer","title":"\ud83d\ude80 Start using the <code>ChromAnalyzer</code>","text":"<p>The workflow for processing chromatographic data with the <code>ChromAnalyzer</code> is as follows:</p> <p>If you use the example data, familiarize yourself with the experimental scenario If you have calibration measurements for quantification, you should process these first.</p> <ol> <li> <p>Follow the instructions on how to find and integrate peaks with OpenChrom as outlined here. If you already processed your data with OpenChrom, you can skip this step.</p> </li> <li> <p>Read the chromatographic data files of one time-course series to create a <code>ChromAnalyzer</code> object. This can as outlined in the documentation.</p> </li> <li> <p>Visualize the chromatograms and the peak areas to check the quality of the data. This can be done as outlined in the documentation. Are all peaks found? Are the peaks integrated correctly?</p> </li> <li> <p>Assign the peaks to the respective compounds. This can be done as outlined in the documentation.</p> </li> <li> <p>If you plan to quantify the compounds, you find the instructions here.</p> </li> <li> <p>Lastly, you can export the data to an EnzymeML document. This can be done as outlined in the documentation.</p> </li> </ol>"},{"location":"usecases/chromatography/#if-something-doesnt-work","title":"\ud83d\udc1e If something doesn't work","text":"<p>Please let us know and we will help you.</p> <p>Alternatively, use ChatGPT to ask for help. Therefore, copy and past the error message of the code cell into the chat and ask for help. The chatbot can mostly provide you with helpful. Furthermore, you can ask follow-up questions to get a better understanding of the problem.</p>"},{"location":"usecases/general/","title":"5th EnzymeML Workshop","text":"<p>24.-26.9.2024, Hotel Jagdschloss Niederwald, R\u00fcdesheim, Germany</p> <p>Organizers: Carsten Kettner, J\u00fcrgen Pleiss, Santiago Schnell Supported by: Beilstein Institute, Frankfurt, and the EU COST Action COZYME</p> <p>We are glad to invite you to our 5th EnzymeML Workshop at the Hotel Jagdschloss Niederwald in R\u00fcdesheim (Germany) on 24.-26.9.2024. R\u00fcdesheim can conveniently be reached by train from Frankfurt airport (1\u00bd h). During the three-day meeting, we will demonstrate and explore the application of our EnzymeML platform during the first EnzymeML Training Course, discuss challenges (especially data acquisition and data analysis), and jointly plan the next steps. We would be glad if you and your co-worker(s) would participate, contribute a dataset for testing, give a talk, and contribute to the discussion.</p> <p>The Beilstein-Institut will cover conference costs, and the EU COST Action COZYME \"Pan-European Network on Computational Redesign of Enzymes\" (CA2116), will cover accommodation and travel costs.</p> <p>Please find more details at on the Beilstein workshop website</p>"},{"location":"usecases/hackathon/","title":"Hackathon: Managing Your Own Data with EnzymeML Tools","text":"<p>This session is designed to familiarize participants with the EnzymeML tools through an interactive workshop. It begins with an introduction to the EnzymeML Suite, a comprehensive grapgical application for creating and visualizing EnzymeML documents. The session will also highlight interoperability with various libraries, showcasing integrations with tools like MTPHandler, NMRPy, and Catalax to enhance versatility and functionality. Thereafter, brought datasets will be read in, with the EnzymeML tools <code>chromatopy</code> for chromatographic measurements, <code>MTPHandler</code>, as well as <code>nmrpy</code></p>"},{"location":"usecases/hackathon/#requirements","title":"Requirements","text":"<p>To participate in the hands-on session, the following hardware and software are required:</p> <ul> <li>Laptop with an up-to-date operating system (e.g., recent Windows, macOS, or Linux operating system)</li> <li>Anaconda installation:</li> </ul> <p>Anaconda simplifies installing and managing Python, Jupyter, and essential tools. It bundles everything you need, including numerous libraries, making it perfect for beginners and advanced users.</p>"},{"location":"usecases/hackathon/#python-libraries","title":"Python Libraries","text":"<p>For this session, the following Python libraries will be used, each serving a specific purpose:</p> <ul> <li> <p>Chromatopy   A versatile library used for processing chromatographic data.</p> </li> <li> <p>MTPHandler   A library for handling data from microtiter plate (MTP) readers. It supports various file formats and provides tools for data processing.</p> </li> <li> <p>NMRPy   A library that facilitates the analysis of Nuclear Magnetic Resonance (NMR) data. It helps in spectral processing, visualization, and interpretation of (time-course) NMR experiments.</p> </li> <li> <p>Catalax   A computational library for simulating catalytic processes and enzyme-catalyzed reactions based on JAX. Catalax offers tools for integration, parameter estimation and neural ordinary differential equations.</p> </li> <li> <p>Basico/COPASI a   Basico is a Python interface for COPASI, a widely-used software for simulating and analyzing biochemical networks. Basico provides Pythonic access to COPASI\u2019s features, such as simulating models, parameter estimation, and sensitivity analysis.</p> </li> </ul> <p>Installation of the required libraries will be covered during the workshop.</p>"},{"location":"usecases/hackathon/#bringing-your-own-data","title":"Bringing Your Own Data","text":"<p>If you plan to utilize your own data, please refer to the following list of supported devices and file formats. However, if you don't have your own data that meets these requirements, you can use prepared datasets provided during the workshop.</p> <ul> <li>Plate reader data   please refer to the supported formats in the documentation of <code>MTPHandler</code></li> <li>Chromatographic data   please refer to the supported formats and data preparation in the documentation of <code>chromatopy</code></li> <li>NMR data   FIDs of NMR measurements (e.g., Bruker, Varian)</li> </ul> <p>You should also bring data from calibration measurements if applicable for your data analysis.</p>"},{"location":"usecases/hackathon/#agenda","title":"Agenda","text":"<p>The hackathon session will start with an introduction in the EnzymeML Suite and how it can be used to capture an experiment with its graphical user interface. Thereafter, either onw datasets or prepared data sets can be processed with the EnzymeML Python tools in a Jupyter Notebook therefore the mentioned Anaconda installation is required. The following workflow illustrates the steps for each of the supported analytical instruments and the optional subsequent data analysis steps:</p> <pre><code>graph LR\n    LAB[\"&lt;b&gt;\ud83d\udcd9 Lab Journal&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;pH&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Temperature&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Reaction Time&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Initial Conditions&lt;/i&gt;&lt;br&gt;&lt;/i&gt;\"]\n    A[\ud83c\udf08 Chromatographic Instrument] --&gt;|output| A1[\ud83d\udcc4 Files]\n    B[\ud83d\udd2c Plate Reader] --&gt;|output| B1[\ud83d\udcc4 Files]\n    C[\ud83e\uddf2 NMR] --&gt;|output| C1[\ud83d\udcc4 Files]\n    LAB --&gt;|fill out form| SUITE\n\n    A1 --&gt;|read| D\n    B1 --&gt;|read| E\n    C1 --&gt;|read| F\n\n    subgraph in Jupyter Notebook:\n        subgraph EnzymeML Python Tools\n            D{chromatopy}\n            E{MTPHandler}\n            F{NMRpy}\n        end\n        D --&gt;|transform| EMLD[EnzymeML Object]\n        E --&gt;|transform| EMLD\n        F --&gt;|transform| EMLD\n        EMLD -.-&gt; DS1\n        EMLD &lt;-.-&gt; DS2\n        EMLD -.-&gt; DS3\n        subgraph with Data Science Python Tools:\n            DS1[Determine e.g., yield, conversion, selectivity]\n            DS2[Kinetic Modeling]\n            DS3[Visualization]\n        end\n    end\n    EnzymeMLDocument[\"&lt;b&gt;\ud83d\udcc4 EnzymeML Document&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;SmallMolecules&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Proteins&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Measurements&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Reactions&lt;/i&gt;\"]\n\n    SUITE[\"&lt;b&gt;\ud83d\uddc2\ufe0f EnzymeML Suite&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;create&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;edit&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;simulate&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;visualize&lt;/i&gt;&lt;br&gt;&lt;/i&gt;\"]\n\n    SUITE &lt;---&gt;|read / write| EnzymeMLDocument\n\n    EMLD &lt;--&gt;|read / write| EnzymeMLDocument</code></pre>"},{"location":"usecases/hackathon/#lets-start","title":"\ud83c\udfc1 Let's start!","text":"<ul> <li>\ud83d\udcda EnzymeML Suite</li> <li>\ud83d\udd2c Process Plate Reader Data</li> <li>\ud83c\udf08 Process Chromatographic Data</li> <li>\ud83e\uddf2 Process NMR Data</li> </ul>"},{"location":"usecases/motivation/","title":"\ud83d\ude80 Motivation","text":"<p>The current processing and analysis of catalytic data mainly relies on spreadsheet-based tools. Thus, many manual processing steps are required, which are error-prone and time-consuming and not scalable. The goal of this project is to develop generic Python tools that allow the processing and analysis of catalyzed reaction data in Jupyter Notebooks. Jupyter Notebooks provide an interactive environment where code, data, and documentation coexist seamlessly, making it easy to experiment with data processing and analysis in real-time. This ensures that the entire workflow is transparent, reproducible, and easily shareable with others. Therefore, the Python tools <code>chromatopy</code>, <code>MTPHandler</code> and <code>NMRpy</code> are developed, enabling the processing of raw data from plate readers and chromatographic instruments. These tools act as data harmonization tools, allowing the conversion of raw data into the standardized EnzymeML format while enriching the measured data with metadata on e.g. reaction conditions or catalyst and substrate properties. Thereafter, the data is ready for further analysis, such as yield, conversion, selectivity determination, kinetic modeling, and visualization in a streamlined and reproducible manner.</p> <p>The following diagram illustrates the workflow for each of the analytical instruments and the optional subsequent data analysis steps:</p> <pre><code>graph LR\n    LAB[\"&lt;b&gt;\ud83d\udcd9 Lab Journal&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;pH&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Temperature&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Reaction Time&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Initial Conditions&lt;/i&gt;&lt;br&gt;&lt;/i&gt;\"]\n    A[\ud83c\udf08 Chromatographic Instrument] --&gt;|output| A1[\ud83d\udcc4 Files]\n    B[\ud83d\udd2c Plate Reader] --&gt;|output| B1[\ud83d\udcc4 Files]\n    C[\ud83e\uddf2 NMR] --&gt;|output| C1[\ud83d\udcc4 Files]\n    LAB --&gt;|fill out form| SUITE\n\n    A1 --&gt;|read| D\n    B1 --&gt;|read| E\n    C1 --&gt;|read| F\n\n    subgraph in Jupyter Notebook:\n        subgraph EnzymeML Python Tools\n            D{chromatopy}\n            E{MTPHandler}\n            F{NMRpy}\n        end\n        D --&gt;|transform| EMLD[EnzymeML Object]\n        E --&gt;|transform| EMLD\n        F --&gt;|transform| EMLD\n        EMLD -.-&gt; DS1\n        EMLD &lt;-.-&gt; DS2\n        EMLD -.-&gt; DS3\n        subgraph with Data Science Python Tools:\n            DS1[Determine e.g., yield, conversion, selectivity]\n            DS2[Kinetic Modeling]\n            DS3[Visualization]\n        end\n    end\n    EnzymeMLDocument[\"&lt;b&gt;\ud83d\udcc4 EnzymeML Document&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;SmallMolecules&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Proteins&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Measurements&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;Reactions&lt;/i&gt;\"]\n\n    SUITE[\"&lt;b&gt;\ud83d\uddc2\ufe0f EnzymeML Suite&lt;/b&gt;&lt;br&gt;&lt;br&gt;\n    &lt;i&gt;create&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;edit&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;simulate&lt;/i&gt;&lt;br&gt;\n    &lt;i&gt;visualize&lt;/i&gt;&lt;br&gt;&lt;/i&gt;\"]\n\n    SUITE &lt;---&gt;|read / write| EnzymeMLDocument\n\n    EMLD &lt;--&gt;|read / write| EnzymeMLDocument</code></pre>"},{"location":"usecases/nmrpy/","title":"Process NMR Data","text":"<p>In this hackathon session, you will process your own time-course data from NMR using the <code>NMRpy</code> Python package. Alternatively, if you do not have your own data, or something fails, you can use the provided example data.</p>"},{"location":"usecases/nmrpy/#topics","title":"\ud83d\udcda Topics","text":"<ol> <li>You will get familiar with using Jupyter Notebooks and how you can run Python code locally on your computer.</li> <li>You will learn how to process and enrich your NMR data using the <code>NMRpy</code> Python package.</li> <li>You will yield a structured EnzymeML Document that can be used for further data analysis.</li> </ol>"},{"location":"usecases/nmrpy/#setup","title":"\ud83d\udee0\ufe0f Setup","text":""},{"location":"usecases/nmrpy/#start-jupyter-notebook","title":"Start Jupyter Notebook","text":"<p>Start with opening Anaconda and launching a Jupyter Notebook. If this is the first time you ever used a Jupyter Notebook, you can find a short introduction  here. Otherwise, you can skip this step.</p>"},{"location":"usecases/nmrpy/#setup-a-project-folder-and-notebook","title":"Setup a project folder and notebook","text":"<p>Navigate to your desired location and create a new folder for your project. This folder will contain all the files you will create during this session. Afterwards, create a new Jupyter Notebook in this folder. You can create new folders and the notebook directly from the Jupyter Notebook interface. Therefore, you can use the <code>New</code> button in the top right corner and select <code>Folder</code> or <code>Notebook Python3 (ipykernel)</code>.</p>"},{"location":"usecases/nmrpy/#add-the-data-to-your-project-folder","title":"Add the data to your project folder","text":"<p>If you brought your own NMR data... If you brought your own chromatographic file, add it to the project folder. Please make sure that your data is organized in a way that it can be read by the <code>NMRpy</code> package. You can find the supported formats  in the documentation of <code>NMRpy</code>.</p> <p>If you do not have your own data... If you do not have your own data, you can use the example data set found in the <code>NMRpy_tutorial</code> repository on GitHub in the <code>tutorial/data/</code> directory.</p>"},{"location":"usecases/nmrpy/#install-the-nmrpy-package","title":"Install the <code>NMRpy</code> package","text":"<p>Copy the following code snippet into the first cell of your Jupyter Notebook and run it. You will also find this code snippet in the Notebooks found in the tutorial repository on GitHub. This code snippet will install the <code>NMRpy</code> package and additional dependencies like <code>pyenzyme</code> if they are not already installed. This is a one-time setup and will not be required for future sessions.</p> <pre><code>import sys\nimport subprocess\nimport shutil\nimport importlib\n\ndef install_and_import(package):\n    try:\n        importlib.import_module(package)\n        print(f\"{package} is already installed\")\n    except ImportError:\n        print(f\"Installing {package}\")\n        %pip install {package}\n\n# install git via conda if not installed\nif not shutil.which(\"git\"):\n    print(\"Installing git via conda\")\n    subprocess.run([\"conda\", \"install\", \"-y\", \"git\"])\n    if not shutil.which(\"git\"):\n        print(\"git is not installed\")\n        sys.exit(1)\nprint(\"git is installed\")\n\n# install NMRpy and other packages\ntry:\n    import nmrpy\n    rint(\"NMRpy is already installed\")\nexcept ImportError:\n    print(\"Installing NMRpy...\")\n    %pip install git+https://github.com/NMRPy/nmrpy@adapt-to-pydantic-v2 --quiet\n\ninstall_and_import(\"matplotlib\")\ninstall_and_import(\"ipyfilechooser\")\ninstall_and_import(\"rich\")\ninstall_and_import(\"pyenzyme\")\n\nprint(\"\ud83c\udfc1 All set! Restart the Notebook once and you are ready to go.\")\n</code></pre> <p>After you have run this code snippet, restart the Jupyter Notebook. You can do this by clicking on <code>Kernel</code> &gt; <code>Restart Kernel...</code> in the top menu, or by clicking on the  button in the top.</p> <p>Verify that the installation was successful by running the following code snippet in a new cell:</p> <pre><code>import nmrpy\n</code></pre> <p>If you do not get an error message, the installation was successful and <code>NMRpy</code> is ready to use. Otherwise, please let us know.</p>"},{"location":"usecases/nmrpy/#start-using-the-nmrpy","title":"\ud83d\ude80 Start using the <code>NMRpy</code>","text":"<p>The workflow for processing chromatographic data with <code>NMRpy</code> is as follows:</p> <ol> <li> <p>If you use your own data, you will have to prepare an EnzymeML document containing the relevant experiment metadata as showcased in the tutorial notebook. You will need information on species measured, the reaction(s), and the measurement.</p> </li> <li> <p>Follow the instructions on how to load an NMR dataset as outlined in the official documentation and in the tutorial notebook.</p> </li> <li> <p>Pre-process the data, if necessary, as required by the dataset.</p> </li> <li> <p>Analyze the data to arrive at the desired concentration data and apply it to the EnzymeML document.</p> </li> </ol>"},{"location":"usecases/nmrpy/#if-something-doesnt-work","title":"\ud83d\udc1e If something doesn't work","text":"<p>Please let us know and we will help you.</p> <p>Alternatively, use ChatGPT to ask for help. To do so, copy and past the error message of the code cell into the chat and ask for help. The chatbot can mostly provide you with helpful. Furthermore, you can ask follow-up questions to get a better understanding of the problem.</p>"},{"location":"usecases/plate_reader/","title":"Process Plate Reader Data","text":"<p>In this hackathon session, you will process your own plate reader data using the <code>mtphandler</code> Python package. Alternatively, if you do not have your own data, or something fails, you can use the provided example data.</p>"},{"location":"usecases/plate_reader/#topics","title":"\ud83d\udcda Topics","text":"<ol> <li>You will get familiar with using Jupyter Notebooks and how you can run Python code locally on your computer.</li> <li>You will learn how to process and enrich you plate reader data using the <code>mtphandler</code> Python package.</li> <li>You will yield a structured EnzymeML Document that can be used for further data analysis.</li> </ol>"},{"location":"usecases/plate_reader/#setup","title":"\ud83d\udee0\ufe0f Setup","text":""},{"location":"usecases/plate_reader/#start-jupyter-notebook","title":"Start Jupyter Notebook","text":"<p>Start with opening Anaconda and launching a Jupyter Notebook. If this is the first time you ever used a Jupyter Notebook, you can find a short introduction  here. Otherwise, you can skip this step.</p>"},{"location":"usecases/plate_reader/#setup-a-project-folder-and-notebook","title":"Setup a project folder and notebook","text":"<p>Navigate to your desired location and create a new folder for your project. This folder will contain all the files you will create during this session. Afterwards, create a new Jupyter Notebook in this folder. You can create new folders and the notebook directly from the Jupyter Notebook interface. Therefore, you can use the <code>New</code> button in the top right corner and select <code>Folder</code> or <code>Notebook Python3 (ipykernel)</code>.</p>"},{"location":"usecases/plate_reader/#add-the-data-to-your-project-folder","title":"Add the data to your project folder","text":"<p>If you brought your own plate reader file, add it to the project folder. If you do not have your own data, you can download the provided example data and the respective pre-filled out plate map.</p>"},{"location":"usecases/plate_reader/#install-the-mtphandler-package","title":"Install the <code>mtphandler</code> package","text":"<p>Copy the following code snippet into the first cell of your Jupyter Notebook and run it. This code snippet will install the <code>mtphandler</code> package if it is not already installed. This is a one-time setup and will not be required for future sessions.</p> <pre><code>import sys\nimport subprocess\nimport shutil\n\n# install git via conda if not installed\nif not shutil.which(\"git\"):\n    print(\"Installing git via conda\")\n    subprocess.run([\"conda\", \"install\", \"-y\", \"git\"])\n    if not shutil.which(\"git\"):\n        print(\"git is not installed\")\n        sys.exit(1)\nprint(\"git is installed\")\n\n# install mtphandler\ntry:\n    from mtphandler import PlateManager\n\nexcept ImportError:\n    print(\"Installing mtphandler...\")\n    !pip install git+https://github.com/FAIRChemistry/MTPHandler.git --quiet\n\nprint(\"\ud83c\udfc1 All set! Restart the Notebook once and you are ready to go.\")\n</code></pre> <p>After you have run this code snippet, restart the Jupyter Notebook. You can do this by clicking on <code>Kernel</code> &gt; <code>Restart Kernel...</code> in the top menu, or by clicking on the  button in the top.</p> <p>Verify that the installation was successful by running the following code snippet in a new cell:</p> <pre><code>from mtphandler import PlateManager\n</code></pre> <p>If you do not get an error message, the installation was successful and the <code>PlateManager</code> is ready to use. Otherwise, please let us know.</p>"},{"location":"usecases/plate_reader/#start-using-the-platemanager","title":"\ud83d\ude80 Start using the <code>PlateManager</code>","text":"<p>Information on how to use the <code>PlateManager</code> can be found in the usage section of the MTPHandler documentation.</p> <p>If you brougt your own data... you can adjust the code snippets in the documentation to your needs and process your own data.</p> <p>If you do not have your own data... the provided data set is identical to the one used in the documentation. You can follow the steps in the documentation to process the provided data set.</p>"},{"location":"usecases/plate_reader/#if-something-doesnt-work","title":"\ud83d\udc1e If something doesn't work","text":"<p>Please let us know and we will help you.</p> <p>Alternatively, use ChatGPT to ask for help. Therefore, copy and past the error message of the code cell into the chat and ask for help. The chatbot can mostly provide you with helpful. Furthermore, you can ask follow-up questions to get a better understanding of the problem.</p>"},{"location":"usecases/schedule/","title":"Programme","text":""},{"location":"usecases/schedule/#2492024","title":"24.9.2024","text":""},{"location":"usecases/schedule/#session-1-status-and-application-of-the-enzymeml-platform","title":"Session 1: Status and Application of the EnzymeML Platform","text":"Time Talk 9:00 J\u00fcrgen Pleiss:Welcome and overview on EnzymeML activities 9:30 Jan Range, Max H\u00e4ussler, Torsten Giess (U.Stuttgart):Demonstration of EnzymeML tools 12:30 End of session 1 and lunch"},{"location":"usecases/schedule/#session-2-hackathon-managing-your-own-data","title":"Session 2: Hackathon: Managing Your Own Data","text":"<p>Find more information on the hackathon session here.</p> Time Talk 14:00 Jan Range, Max H\u00e4ussler, Torsten Giess &amp; all participants:Read in and analyze your own datasets 17:00 End of session 2 17:15 Excursion 19:30 Dinner"},{"location":"usecases/schedule/#2592024","title":"25.9.2024","text":""},{"location":"usecases/schedule/#session-3-acquisition-of-data-and-metadata","title":"Session 3: Acquisition of Data and Metadata","text":"Time Talk 9:00 Johann Rohwer (U.Stellenbosch):LabNexus: An open-source enzyme kinetics data automation web application 9:45 Marilize Le Roes-Hill (CPUT, Cape Town):Expanding the enzyme \u2018reactome\u2019 via high-throughput experimentation \u2013 is reproducibility an issue? 10:30 Coffee break 11:00 Nicole Jung (KIT, Karlsruhe):tba 11:45 Katrin Rosenthal (Constructor U., Bremen):Challenges and solutions for digital (un)structured data in biocatalysis 12:30 End of session 3 and lunch"},{"location":"usecases/schedule/#session-4-data-analysis-modelling-optimization-and-design-of-experiment","title":"Session 4: Data Analysis, Modelling, Optimization, and Design of Experiment","text":"Time Talk 14:00 Zvjezdana Findrik (U.Zagreb):Modelling approach in the biocatalytic process optimization and design 14:45 Andreas Bommarius (Georgia Tech, Atlanta):Biocatalysis in multiphase reactors 15:30 Coffee break 16:00 Jenny Andexer (U.Freiburg):When cascades turn into cycles - from cofactor supply to regeneration 16:45 Sebastian H\u00f6pfl (U.Stuttgart):Optimal experimental design in biocatalysis - from Gaussian processes towards Bayesian statistics 17:30 End of session 4 19:30 Dinner"},{"location":"usecases/schedule/#2692024","title":"26.9.2024","text":""},{"location":"usecases/schedule/#session-5-infrastructure-what-comes-next","title":"Session 5: Infrastructure: What Comes Next?","text":"Time Talk 9:00 Carine Vergne-Vaxelaire (Genoscope, \u00c9vry):High throughput screening data on enzyme activity: a first proposal for user-friendly data integration into EnzymeML workflow 9:45 Frank Bergmann (U.Heidelberg):Future-proofing software infrastructure: enhancing EnzymeML with WebAssembly 10:30 Coffee break 11:00 Ulrike Wittig (HITS, Heidelberg):Using EnzymeML to exchange and publish reaction kinetics data in SABIO-RK 11:45 Carsten Kettner (Beilstein I., Frankfurt):Extending STRENDA DB light 12:30 End of session 5 and lunch"},{"location":"usecases/schedule/#session-6-outlook-and-planning","title":"Session 6: Outlook and Planning","text":"Time Talk 14:00 Santiago Schnell (U.Notre Dame):Round robin study on measuring enzyme reactions 14:30 Mehdi Davari (IBP, Halle):Critical Assessment of Enzyme Design 15:00 Final remarks 15:30 End of session 6 19:30 Dinner"},{"location":"usecases/suite/","title":"EnzymeML Suite","text":"<p>In order to install the EnzymeML Suite, choose one of the following options depending on your operating system:</p> <ul> <li>Windows</li> <li>Windows (MSI)</li> <li>macOS (Apple Silicon)</li> <li>macOS (Intel)</li> <li>Ubuntu</li> </ul>"},{"location":"usecases/suite/#build-the-enzymeml-suite-from-source","title":"Build the EnzymeML Suite from Source","text":"<p>If you experience any issues, you can build the EnzymeML Suite from source. Follow the steps below to set up and compile the project.</p>"},{"location":"usecases/suite/#prerequisites","title":"Prerequisites","text":"<p>First, ensure your system is set up for Tauri. You can follow the instructions here to install the required tools.</p>"},{"location":"usecases/suite/#building-the-enzymeml-suite","title":"Building the EnzymeML Suite","text":"<p>Once the prerequisites are installed, open a terminal and run the following commands:</p> <pre><code># Clone the latest release of the EnzymeML Suite\ngit clone https://github.com/JR-1991/enzymeml-suite.git\ngit checkout tags/v0.0.1\ncd enzymeml-suite\n\n# Build the EnzymeML Suite\ncargo tauri build --release\n</code></pre> <p>After the build completes, you should receive a message confirming the build was successful. The terminal will also display the path to the installer for the EnzymeML Suite.</p>"}]}